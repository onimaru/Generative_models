{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder - MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "* Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(x):\n",
    "    x = x.data.numpy().reshape(data1.shape[1],data1.shape[2])\n",
    "    plt.imshow(x,cmap='gray_r')\n",
    "    plt.show()\n",
    "    \n",
    "def generate_samples(encoder,decoder,mb_size):\n",
    "    for _, batch in enumerate(loader):\n",
    "        X = Variable(batch[0]).to(device)\n",
    "        X_size = X.shape[0]\n",
    "        X = X.reshape(X_size,28*28).to(device)\n",
    "        z = Variable(torch.randn(X_size, Z_dim)).to(device)\n",
    "        z_mu, z_var = encoder(X)\n",
    "        z = sample_z(z_mu, z_var,X_size)\n",
    "        X_sample = decoder(z)\n",
    "    return X_sample[:mb_size]\n",
    "\n",
    "def plot_n_random_digits(x,labels=None,n_images=9,title='Digits'):\n",
    "    \"\"\"Ate 20 imagens\"\"\"\n",
    "    indices = np.random.choice(x.shape[0],size=n_images)\n",
    "    x = x[indices].data.numpy()\n",
    "    if isinstance(labels, torch.IntTensor):\n",
    "        sample_labels = labels[indices].data.numpy()\n",
    "    else: sample_labels = ['None']*len(indices)\n",
    "    x = x.reshape(n_images,data1.shape[1],data1.shape[2])\n",
    "    plt.clf()\n",
    "    plt.style.use('seaborn-muted')\n",
    "    fig, axes = plt.subplots(2,10, figsize=(15,3), sharex=True, sharey=True,\n",
    "                             subplot_kw=dict(adjustable='box', aspect='equal'))\n",
    "    for i in range(n_images):\n",
    "        subplot_row = i//10\n",
    "        subplot_col = i%10  \n",
    "        ax = axes[subplot_row, subplot_col]\n",
    "        plottable_image = x[i,:]\n",
    "        ax.imshow(plottable_image, cmap='gray_r')\n",
    "        ax.set_title('Digit Label: {}'.format(sample_labels[i]))\n",
    "        ax.set_xbound([0,28])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_label(label):\n",
    "    chosen_label = label\n",
    "    batch = 1000\n",
    "    y_sample = np.zeros(shape=[batch, y_dim])\n",
    "    y_sample[:,chosen_label] = 1\n",
    "    y_sample_tc = torch.Tensor(y_sample).type(torch.IntTensor)\n",
    "    plot_n_random_digits(G(Variable(torch.randn(batch, Z_dim)).cuda(),\n",
    "                         y_sample_tc.type(torch.FloatTensor).cuda()).cpu(),\n",
    "                         labels=torch.max(y_sample_tc,dim=1)[1].type(torch.IntTensor),\n",
    "                         n_images=20,title='conditional_gan_generated_{}_{}_'.format(chosen_label,epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.MNIST('./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_images = '/home/ninja/MNIST/train-images.idx3-ubyte'\n",
    "file_labels = '/home/ninja/MNIST/train-labels.idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_images,'rb') as f:\n",
    "    magic, size = struct.unpack(\">II\", f.read(8))\n",
    "    nrows, ncols = struct.unpack(\">II\", f.read(8))\n",
    "    data1 = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "    data1 = data1.reshape((size, nrows, ncols))\n",
    "\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data1[4,:,:], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1.reshape(data1.shape[0],data1.shape[1]*data1.shape[2])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_labels,'rb') as f:\n",
    "    labels = np.fromfile(f, dtype=np.dtype(np.uint8).newbyteorder('>'))\n",
    "\n",
    "labels = labels[8:]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "    1- Escalar os dados entre zero e 1\n",
    "    2- Transformar os dados (X e y) em um tensor do tipo float\n",
    "        Ex: torch.Tensor(x).type(torch.FloatTensor)\n",
    "    3- Verificar se as dimensões e tipo estão corretas:\n",
    "        X_dim = (60k,784), y_dim = (60k,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "scaler = \n",
    "data = scaler.fit_transform(data)\n",
    "# 2\n",
    "X_tc = \n",
    "y_tc = \n",
    "# 3\n",
    "print(X_tc.shape, X_tc.type(),y_tc.shape, y_tc.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4- Plotar uma observação qualquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digit(    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5- Plotar 20 dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_random_digits(   ,n_images=   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "    1- Definir um batch_size\n",
    "    2- Determinar as dimensões usadas nas redes neurais\n",
    "    3- Definir quantas camadas serão usadas tb seus tamanhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "mb_size = \n",
    "# 2\n",
    "Z_dim = \n",
    "X_dim = \n",
    "y_dim = \n",
    "# 3\n",
    "a_dim, b_dim, ... = [  ,  , ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4- Passar os dados para o DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset = Data.TensorDataset(...)\n",
    "loader = Data.DataLoader(\n",
    "        dataset = torch_dataset,\n",
    "        batch_size = mb_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=12\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo as redes neurais\n",
    "    1- Ensira o número de camadas escolhidas no construtor da classe Encoder usando camadas lineares\n",
    "        Ex: torch.nn.Linear(dimensão de entrada, dimensão de saída)\n",
    "    2- No método forward use uma função relu em todas as camadas em sequência\n",
    "        Ex: h = F.relu(self.hidden1(X))\n",
    "    3- O Encoder deve ter duas saídas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        # 1\n",
    "        self.hidden1 = torch.nn.Linear(X_dim, a_dim)\n",
    "        self.hidden2 = ...\n",
    "        ...\n",
    "    \n",
    "    def forward(self,X):\n",
    "        # 2\n",
    "        h = F.relu(self.hidden1(X))\n",
    "        h = F.relu(self.hidden2(h))\n",
    "        ...\n",
    "        # 3\n",
    "        mu = \n",
    "        log_sigma = \n",
    "        return mu, log_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4- Construa a função que faz a amostragem de z\n",
    "        Ex: epsilon = Variable(torch.randn(mb_size, Z_dim)).to(device)\n",
    "            z = (mu + torch.exp(log_sigma / 2) * epsilon).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(mu, log_sigma,mb_size):\n",
    "    epsilon = Variable(torch.randn(mb_size, Z_dim)).to(device)\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6- Construa o Decoder. Ele é quase o inverso do Decoder com a diferença que recebe uma entrada ao invés de duas\n",
    "    7- Aplique a ativação sigmoid na saída do Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        # 6\n",
    "        self.hidden1 = torch.nn.Linear(Z_dim, ...)\n",
    "    \n",
    "    def forward(self,z):\n",
    "        h = F.relu(self.hidden1(z))\n",
    "        ...\n",
    "        # 7\n",
    "        out = torch.sigmoid(...)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciando e definindo o Otimizador\n",
    "    1- Instancie o Encoder e o Decoder como no exemplo abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede1 = Rede1(ngpu).to(device)\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    rede1 = nn.DataParallel(rede1, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2- Defina uma taxa de aprendizado\n",
    "    3- Crie uma lista com os parâmetros da duas redes e passe par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = \n",
    "params = list(rede1.parameters()) + list(rede1.parameters())\n",
    "optimizer = optim.Adam(params, lr=lr, betas=(0.9,0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4- Aplique a inicialicação de pesos nas duas redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight).to(device)\n",
    "        m.bias.data.fill_(0.001)\n",
    "\n",
    "#Inicializar pesos das redes\n",
    "rede1.apply(init_weights)\n",
    "...\n",
    "\n",
    "# lista para guardar as informações das perdas\n",
    "loss_his = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5- Se já tiver um modelo salvo pode carregar os pessos com o código abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved networks\n",
    "# encoder.load_state_dict(torch.load('models/encoder_mnist.pt'))\n",
    "# decoder.load_state_dict(torch.load('models/decoder_mnist.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6- Verifique se as redes saíram como você esperava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rede1)\n",
    "print(rede2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando\n",
    "    1- Defina um número de épocas\n",
    "    2- Defina o X_size como o dimensão zero de X\n",
    "    3- Passe o X para o Encoder devolver suas saídas\n",
    "    4- Faça a amostragem de z\n",
    "    5- Passe z para o Decoder retornar X\n",
    "    6- Calcule o erro de reconstrução com a função de perda:\n",
    "        F.binary_cross_entropy(X_falso, X_real, reduction='sum')\n",
    "    7- Calcule a divergência KL utilizando sua forma fechada:\n",
    "        0.5*sum(exp(z_var) + z_mu**2 - 1. - z_var)\n",
    "    8- Some as duas para obter a perda total\n",
    "    9- Calcule os gradientes usando loss.backward()\n",
    "    10- Atualize o otimizador usando optimizer.step() e zere os gradientes para a próxima iteração com optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1\n",
    "epochs = \n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for step, batch_x in enumerate(loader):\n",
    "        X = Variable(batch_x[0]).to(device)\n",
    "        # 2\n",
    "        X_size = \n",
    "        # 3\n",
    "        z_mu, z_var = encoder(  )\n",
    "        # 4\n",
    "        z = sample_z(   ,   ,X_size)\n",
    "        # 5\n",
    "        X_sample = decoder(   )\n",
    "        \n",
    "        # 6\n",
    "        recon_loss = ...\n",
    "        # 7\n",
    "        kl_loss = torch.mean(    * torch.sum(       , dim=1))\n",
    "        # 8\n",
    "        loss = ...\n",
    "        # 9\n",
    "        ...\n",
    "        # 10\n",
    "        ...\n",
    "        ...\n",
    "\n",
    "        # Recolher dados das funções de perda\n",
    "        loss_his.append(loss.data)\n",
    "\n",
    "    # Mostrar dados ao longo das epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch-{}| Average loss: {:.5f}'.format(epoch, loss.mean().data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "    1- Verifique a evolução da perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_his)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2- Salve o modelo se quiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# torch.save(encoder.state_dict(), 'models/encoder_mnist.pt')\n",
    "# torch.save(decoder.state_dict(), 'models/decoder_mnist.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3- Gera alguns dados e comparar com os dados verdadeiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fake = generate_samples(encoder,decoder,mb_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_random_digits(X_fake.cpu(),labels=None,n_images=20,title='Digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_random_digits(X_tc,n_images=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bônus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_sample():\n",
    "    X_samples = torch.Tensor().to(device)\n",
    "    Z_samples = torch.Tensor().to(device)\n",
    "    for step, batch in enumerate(loader):\n",
    "        X = Variable(batch[0]).to(device)\n",
    "        z_mu, z_var = encoder(X)\n",
    "        z = sample_z(z_mu, z_var,X.shape[0])\n",
    "        X_samples = torch.cat([X_samples,decoder(z)],dim=0)\n",
    "        Z_samples = torch.cat([Z_samples,z],dim=0)\n",
    "    return X_samples,Z_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samples,Z_samples = generate_full_sample()\n",
    "X_samples.shape,Z_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "X_fake = X_samples[:sample_size].cpu().data.numpy()\n",
    "X_real = X_tc[:sample_size].cpu().data.numpy()\n",
    "Z = Z_samples[:sample_size].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando o \"espaço de features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_real = umap.UMAP(n_neighbors=25,min_dist=0.3,n_epochs=2000,\n",
    "                      metric='euclidean').fit_transform(X_real)\n",
    "embedding_fake = umap.UMAP(n_neighbors=25,min_dist=0.3,n_epochs=2000,\n",
    "                      metric='euclidean').fit_transform(X_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x=embedding_real[:,0],y=embedding_real[:,1],label=\"real\")\n",
    "plt.scatter(x=embedding_fake[:,0],y=embedding_fake[:,1],label=\"fake\")\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = 0\n",
    "plt.figure(figsize=(10,6))\n",
    "embedding_real_ = embedding_real[np.where(labels[:sample_size]==digit)]\n",
    "embedding_fake_ = embedding_fake[np.where(labels[:sample_size]==digit)]\n",
    "labels_ = [np.where(labels[:sample_size]==0)]\n",
    "plt.scatter(x=embedding_real_[:,0],y=embedding_real_[:,1],label=\"real\")\n",
    "plt.scatter(x=embedding_fake_[:,0],y=embedding_fake_[:,1],label=\"fake\")\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in range(10):\n",
    "    embedding_real_ = embedding_real[np.where(labels[:sample_size]==i)]\n",
    "    labels_ = [np.where(labels[:sample_size]==0)]\n",
    "    plt.scatter(x=embedding_real_[:,0],y=embedding_real_[:,1],label=i)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in range(10):\n",
    "    embedding_fake_ = embedding_fake[np.where(labels[:sample_size]==i)]\n",
    "    labels_ = [np.where(labels[:sample_size]==0)]\n",
    "    plt.scatter(x=embedding_fake_[:,0],y=embedding_fake_[:,1],label=i)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando o \"espaço latente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_Z = umap.UMAP(n_neighbors=25,min_dist=0.3,n_epochs=2000,\n",
    "                      metric='euclidean').fit_transform(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in range(10):\n",
    "    embedding_Z_ = embedding_Z[np.where(labels[:sample_size]==i)]\n",
    "    labels_ = [np.where(labels[:sample_size]==0)]\n",
    "    plt.scatter(x=embedding_Z_[:,0],y=embedding_Z_[:,1],label=i)\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas topológicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gs\n",
    "import gudhi as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Geometry Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometry_score(X_real,X_fake,L_0=64, gamma=1.0/128,  i_max=100, n=500):\n",
    "    rlt_fake = gs.rlts(X_fake, L_0=L_0, gamma=gamma,  i_max=i_max, n=n)\n",
    "    rlt_real = gs.rlts(X_real, L_0=L_0, gamma=gamma,  i_max=i_max, n=n)\n",
    "    return gs.geom_score(rlt_real, rlt_fake), np.mean(rlt_real, axis=0), np.mean(rlt_fake, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "geo_score, mrlt_real, mrlt_fake = geometry_score(X_real,X_fake,L_0=64, gamma=1.0/128,  i_max=200, n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fancy_plot(mrlt_fake, label='MRLT of fake data',color='blueviolet')\n",
    "gs.fancy_plot(mrlt_real, label='MRLT of real data',color='limegreen')\n",
    "plt.title('Geometry Score: {:.3f}'.format(geo_score))\n",
    "plt.xlim([0, 110])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Persistence Homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_real_ripscomplex = gd.RipsComplex(points=X_real,max_edge_length=7.0) \n",
    "Rips_simplex_tree_X_real = X_real_ripscomplex.create_simplex_tree(max_dimension=2)\n",
    "BarCodes_Rips0_real = Rips_simplex_tree_X_real.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_fake_ripscomplex = gd.RipsComplex(points=X_fake,max_edge_length=7.0) \n",
    "Rips_simplex_tree_X_fake = X_fake_ripscomplex.create_simplex_tree(max_dimension=2)\n",
    "BarCodes_Rips0_fake = Rips_simplex_tree_X_fake.persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "plot = gd.plot_persistence_barcode(BarCodes_Rips0_real)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data\n",
    "plot = gd.plot_persistence_barcode(BarCodes_Rips0_fake)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Real data: Number o holes in {i} dimension: {len(Rips_simplex_tree_X_real.persistence_intervals_in_dimension(i))}\")\n",
    "    print(f\"Fake data: Number o holes in {i} dimension: {len(Rips_simplex_tree_X_fake.persistence_intervals_in_dimension(i))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.plot_persistence_diagram(BarCodes_Rips0_real);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.plot_persistence_diagram(BarCodes_Rips0_fake);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
